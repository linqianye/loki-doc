# 用Loki收集日志

在安装并运行Loki之后，您可能希望从其他应用程序获取日志。

要将应用程序日志放到Loki中，需要编辑 [Promtail](clients.md#promtail) 的配置文件。

[Promtail 配置](clients.md#promtail#configuration) 中提供了有关配置Promtail的详细信息。

以下说明应该可以帮助您入门。

1. 如果您还没有下载Promtail配置文件。请找到它的位置并下载文件因为在运行二进制文件时需要使用它。

   ```bash
   wget https://raw.githubusercontent.com/grafana/loki/v2.2.0/cmd/promtail/promtail-local-config.yaml
   ```

2. 在您选择的文本编辑器中打开配置文件。它应该类似于：

   ```yaml
   server:
     http_listen_port: 9080
     grpc_listen_port: 0
   
   positions:
     filename: /tmp/positions.yaml
   
   clients:
     - url: http://loki:3100/loki/api/v1/push
   
   scrape_configs:
   - job_name: system
     static_configs:
     - targets:
         - localhost
       labels:
         job: varlogs
         __path__: /var/log/*log
   ```

`scrape_configs`下面的七行是将 Loki 产生的日志发送给 Loki，然后在命令行和 http://localhost:3100/metrics 中输出它们。

1. 复制`scrape_configs`下的七行，然后将它们粘贴到原始文件中（您也可以编辑原始文件的七行）。

   下面是一个将默认Grafana安装的日志发送到Loki的示例。我们更新了以下字段：

   - **job_name** - 用来区分从其他日志组收集的日志。
   - **targets** - 对于静态配置，targets是可选的，但是通常被定义，因为在Promtail的旧版本中它不是可选的。这是直接使用Prometheus服务发现代码的组件，需要这个条目。
   - **labels** - 应用于此定义抓取的每个日志行的静态标签。例如环境名称、作业名称或应用程序名称。
   - **path** - 希望 Loki 使用的日志存储位置的路径。

   ```yaml
   - job_name: grafana
     static_configs:
     - targets:
         - grafana
       labels:
         job: grafana
         __path__: "C:/Program Files/GrafanaLabs/grafana/data/log/grafana.log"
   ```

2. 输入以下命令来运行 Promtail。下面的示例假设您已将配置文件与二进制文件放在同一目录中。

   **Windows**

   ```cmd
   `.\promtail-windows-amd64.exe --config.file=promtail-local-config.yaml`
   ```

   **Linux**

   ```bash
   ./promtail-linux-amd64 -config.file=promtail-local-config.yaml
   ```

现在应该可以看到应用程序日志了。如果您使用的是Grafana，则可能需要刷新实例以查看日志。



# Loki与Grafana

[6.0](https://grafana.com/grafana/download/6.0.0)版本以后的 Grafana 内置了对 Loki 的支持 。强烈建议使用 [6.3](https://grafana.com/grafana/download/6.3.0)或更高版本的grafana来使用新的[LogQL](https://grafana.com/docs/loki/v2.2.0/logql/)功能。

1. 登录到您的 Grafana。如果这是您第一次运行 Grafana，则用户名和密码都默认为`admin`。
2. 在 Grafana 中，通过左侧边栏上的齿轮图标转到`Configuration`> `Data Sources`。
3. 单击`Add data source`按钮。
4. 从列表中选择 Loki。
5. http URL 字段应该是您的 Loki 服务器的地址。例如，在本地运行或使用端口映射与 Docker 一起运行时，地址可能是`http://localhost:3100`。使用 docker-compose 或 Kubernetes 运行时，地址很可能是`http://loki:3100`。
6. 要查看日志，请单击侧边栏上的Explore，在左上角的下拉列表中选择 Loki 数据源，然后使用Log labels按钮选择日志流 。
7. 通过阅读 Loki 的查询语言[LogQL](logql.md)了解有关查询的更多信息。

阅读[Grafana 文档](http://docs.grafana.org/features/explore)中关于Grafana的Explore特性的更多信息，以及如何使用Loki搜索和过滤日志。

> 要通过配置来配置数据源，请参阅 Grafana 文档中的[Configuring Grafana via Provisioning](http://docs.grafana.org/features/datasources/loki/#configure-the-datasource-with-provisioning)并确保按照上述方式调整 URL。



# 使用 LogCLI 查询 Loki

如果您更喜欢命令行界面，LogCLI还允许用户对Loki服务器运行LogQL查询。

## 安装

### 二进制（推荐）

每个版本都包含logcli的二进制文件，可以在[Releases 页面](https://github.com/grafana/loki/releases)上找到。

### 源码安装

使用`go get`安装`logcli`到`$GOPATH/bin`：

```bash
$ go get github.com/grafana/loki/cmd/logcli
```

## 使用

### 例子

如果您在 Grafana Cloud 上运行，请使用：

```bash
$ export LOKI_ADDR=https://logs-us-west1.grafana.net
$ export LOKI_USERNAME=<username>
$ export LOKI_PASSWORD=<password>
```

否则，您可以直接将 LogCLI 指向本地实例，而无需用户名和密码：

```bash
$ export LOKI_ADDR=http://localhost:3100
```

> 注意：如果您在代理服务器后面运行 Loki 并且配置了身份验证，则还必须相应地传入 LOKI_USERNAME 和 LOKI_PASSWORD。

```bash
$ logcli labels job
https://logs-dev-ops-tools1.grafana.net/api/prom/label/job/values
cortex-ops/consul
cortex-ops/cortex-gw
...

$ logcli query '{job="cortex-ops/consul"}'
https://logs-dev-ops-tools1.grafana.net/api/prom/query?query=%7Bjob%3D%22cortex-ops%2Fconsul%22%7D&limit=30&start=1529928228&end=1529931828&direction=backward&regexp=
Common labels: {job="cortex-ops/consul", namespace="cortex-ops"}
2018-06-25T12:52:09Z {instance="consul-8576459955-pl75w"} 2018/06/25 12:52:09 [INFO] raft: Snapshot to 475409 complete
2018-06-25T12:52:09Z {instance="consul-8576459955-pl75w"} 2018/06/25 12:52:09 [INFO] raft: Compacting logs from 456973 to 465169
...

$ logcli series -q --match='{namespace="loki",container_name="loki"}'
{app="loki", container_name="loki", controller_revision_hash="loki-57c9df47f4", filename="/var/log/pods/loki_loki-0_8ed03ded-bacb-4b13-a6fe-53a445a15887/loki/0.log", instance="loki-0", job="loki/loki", name="loki", namespace="loki", release="loki", statefulset_kubernetes_io_pod_name="loki-0", stream="stderr"}
```

### 批量查询

从 Loki 1.6.0 开始，`logcli`支持对 Loki 日志批量查询。

如果将一个查询的`--limit`（默认值为30）设置为一个很大的数字，比如`--limit=10000`，那么logcli会自动将这个请求批量发送给Loki。

默认批量大小为`1000`.

Loki 对查询中返回的最大行数有服务器端限制（默认为 5000）。

只要`--batch`大小小于服务器限制，批处理允许您发出比服务器端限制大的请求。

请注意，在查询元数据是为每个批次打印的`stderr`。通过设置`--quiet`标志以停止此行为。

### 配置

配置值按以下顺序（从低到高）考虑：

- 环境变量
- 命令行标识

### 详情

```bash
$ logcli help
usage: logcli [<flags>] <command> [<args> ...]

A command-line for loki.

Flags:
      --help             Show context-sensitive help (also try --help-long and --help-man).
      --version          Show application version.
  -q, --quiet            Suppress query metadata.
      --stats            Show query statistics.
  -o, --output=default   Specify output mode [default, raw, jsonl]. raw suppresses log labels and timestamp.
  -z, --timezone=Local   Specify the timezone to use when formatting output timestamps [Local, UTC].
      --cpuprofile=""    Specify the location for writing a CPU profile.
      --memprofile=""    Specify the location for writing a memory profile.
      --addr="http://localhost:3100"
                         Server address. Can also be set using LOKI_ADDR env var.
      --username=""      Username for HTTP basic auth. Can also be set using LOKI_USERNAME env var.
      --password=""      Password for HTTP basic auth. Can also be set using LOKI_PASSWORD env var.
      --ca-cert=""       Path to the server Certificate Authority. Can also be set using LOKI_CA_CERT_PATH env var.
      --tls-skip-verify  Server certificate TLS skip verify.
      --cert=""          Path to the client certificate. Can also be set using LOKI_CLIENT_CERT_PATH env var.
      --key=""           Path to the client certificate key. Can also be set using LOKI_CLIENT_KEY_PATH env var.
      --org-id=""        adds X-Scope-OrgID to API requests for representing tenant ID. Useful for requesting tenant data when
                         bypassing an auth gateway.

Commands:
  help [<command>...]
    Show help.

  query [<flags>] <query>
    Run a LogQL query.

    The "query" command is useful for querying for logs. Logs can be returned in a few output modes:

      raw: log line
      default: log timestamp + log labels + log line
      jsonl: JSON response from Loki API of log line

    The output of the log can be specified with the "-o" flag, for example, "-o raw" for the raw output format.

    The "query" command will output extra information about the query and its results, such as the API URL, set of common labels,
    and set of excluded labels. This extra information can be suppressed with the --quiet flag.

    While "query" does support metrics queries, its output contains multiple data points between the start and end query time.
    This output is used to build graphs, like what is seen in the Grafana Explore graph view. If you are querying metrics and just
    want the most recent data point (like what is seen in the Grafana Explore table view), then you should use the "instant-query"
    command instead.

  instant-query [<flags>] <query>
    Run an instant LogQL query.

    The "instant-query" command is useful for evaluating a metric query for a single point in time. This is equivalent to the
    Grafana Explore table view; if you want a metrics query that is used to build a Grafana graph, you should use the "query"
    command instead.

    This command does not produce useful output when querying for log lines; you should always use the "query" command when you
    are running log queries.

    For more information about log queries and metric queries, refer to the LogQL documentation:

    https://grafana.com/docs/loki/v2.2.0/logql/

  labels [<flags>] [<label>]
    Find values for a given label.

  series [<flags>] <matcher>
    Run series query.

$ logcli help query
usage: logcli query [<flags>] <query>

Run a LogQL query.

The "query" command is useful for querying for logs. Logs can be returned in a few output modes:

  raw: log line
  default: log timestamp + log labels + log line
  jsonl: JSON response from Loki API of log line

The output of the log can be specified with the "-o" flag, for example, "-o raw" for the raw output format.

The "query" command will output extra information about the query and its results, such as the API URL, set of common labels, and
set of excluded labels. This extra information can be suppressed with the --quiet flag.

While "query" does support metrics queries, its output contains multiple data points between the start and end query time. This
output is used to build graphs, like what is seen in the Grafana Explore graph view. If you are querying metrics and just want the
most recent data point (like what is seen in the Grafana Explore table view), then you should use the "instant-query" command
instead.

Flags:
      --help               Show context-sensitive help (also try --help-long and --help-man).
      --version            Show application version.
  -q, --quiet              Suppress query metadata.
      --stats              Show query statistics.
  -o, --output=default     Specify output mode [default, raw, jsonl]. raw suppresses log labels and timestamp.
  -z, --timezone=Local     Specify the timezone to use when formatting output timestamps [Local, UTC].
      --cpuprofile=""      Specify the location for writing a CPU profile.
      --memprofile=""      Specify the location for writing a memory profile.
      --addr="http://localhost:3100"
                           Server address. Can also be set using LOKI_ADDR env var.
      --username=""        Username for HTTP basic auth. Can also be set using LOKI_USERNAME env var.
      --password=""        Password for HTTP basic auth. Can also be set using LOKI_PASSWORD env var.
      --ca-cert=""         Path to the server Certificate Authority. Can also be set using LOKI_CA_CERT_PATH env var.
      --tls-skip-verify    Server certificate TLS skip verify.
      --cert=""            Path to the client certificate. Can also be set using LOKI_CLIENT_CERT_PATH env var.
      --key=""             Path to the client certificate key. Can also be set using LOKI_CLIENT_KEY_PATH env var.
      --org-id=""          adds X-Scope-OrgID to API requests for representing tenant ID. Useful for requesting tenant data when
                           bypassing an auth gateway.
      --limit=30           Limit on number of entries to print.
      --since=1h           Lookback window.
      --from=FROM          Start looking for logs at this absolute time (inclusive).
      --to=TO              Stop looking for logs at this absolute time (exclusive).
      --step=STEP          Query resolution step width, for metric queries. Evaluate the query at the specified step over the time
                           range.
      --interval=INTERVAL  Query interval, for log queries. Return entries at the specified interval, ignoring those between.
                           **This parameter is experimental, please see Issue 1779**.
      --batch=1000         Query batch size to use until 'limit' is reached.
      --forward            Scan forwards through logs.
      --no-labels          Do not print any labels.
      --exclude-label=EXCLUDE-LABEL ...
                           Exclude labels given the provided key during output.
      --include-label=INCLUDE-LABEL ...
                           Include labels given the provided key during output.
      --labels-length=0    Set a fixed padding to labels.
      --store-config=""    Execute the current query using a configured storage from a given Loki configuration file.
  -t, --tail               Tail the logs.
      --delay-for=0        Delay in tailing by number of seconds to accumulate logs for re-ordering.
      --colored-output     Show ouput with colored labels.

Args:
  <query>  eg '{foo="bar",baz=~".*blip"} |~ ".*error.*"'

$ logcli help labels
usage: logcli labels [<flags>] [<label>]

Find values for a given label.

Flags:
      --help             Show context-sensitive help (also try --help-long and --help-man).
      --version          Show application version.
  -q, --quiet            Suppress query metadata.
      --stats            Show query statistics.
  -o, --output=default   Specify output mode [default, raw, jsonl]. raw suppresses log labels and timestamp.
  -z, --timezone=Local   Specify the timezone to use when formatting output timestamps [Local, UTC].
      --cpuprofile=""    Specify the location for writing a CPU profile.
      --memprofile=""    Specify the location for writing a memory profile.
      --addr="http://localhost:3100"
                         Server address. Can also be set using LOKI_ADDR env var.
      --username=""      Username for HTTP basic auth. Can also be set using LOKI_USERNAME env var.
      --password=""      Password for HTTP basic auth. Can also be set using LOKI_PASSWORD env var.
      --ca-cert=""       Path to the server Certificate Authority. Can also be set using LOKI_CA_CERT_PATH env var.
      --tls-skip-verify  Server certificate TLS skip verify.
      --cert=""          Path to the client certificate. Can also be set using LOKI_CLIENT_CERT_PATH env var.
      --key=""           Path to the client certificate key. Can also be set using LOKI_CLIENT_KEY_PATH env var.
      --org-id=""        adds X-Scope-OrgID to API requests for representing tenant ID. Useful for requesting tenant data when
                         bypassing an auth gateway.
      --since=1h         Lookback window.
      --from=FROM        Start looking for labels at this absolute time (inclusive).
      --to=TO            Stop looking for labels at this absolute time (exclusive).

Args:
  [<label>]  The name of the label.

$ logcli help series
usage: logcli series --match=MATCH [<flags>]

Run series query.

Flags:
      --help             Show context-sensitive help (also try --help-long and --help-man).
      --version          Show application version.
  -q, --quiet            Suppress query metadata.
      --stats            Show query statistics.
  -o, --output=default   Specify output mode [default, raw, jsonl]. raw suppresses log labels and timestamp.
  -z, --timezone=Local   Specify the timezone to use when formatting output timestamps [Local, UTC].
      --cpuprofile=""    Specify the location for writing a CPU profile.
      --memprofile=""    Specify the location for writing a memory profile.
      --addr="http://localhost:3100"
                         Server address. Can also be set using LOKI_ADDR env var.
      --username=""      Username for HTTP basic auth. Can also be set using LOKI_USERNAME env var.
      --password=""      Password for HTTP basic auth. Can also be set using LOKI_PASSWORD env var.
      --ca-cert=""       Path to the server Certificate Authority. Can also be set using LOKI_CA_CERT_PATH env var.
      --tls-skip-verify  Server certificate TLS skip verify.
      --cert=""          Path to the client certificate. Can also be set using LOKI_CLIENT_CERT_PATH env var.
      --key=""           Path to the client certificate key. Can also be set using LOKI_CLIENT_KEY_PATH env var.
      --org-id=""        adds X-Scope-OrgID to API requests for representing tenant ID. Useful for requesting tenant data when
                         bypassing an auth gateway.
      --since=1h         Lookback window.
      --from=FROM        Start looking for logs at this absolute time (inclusive).
      --to=TO            Stop looking for logs at this absolute time (exclusive).
      --match=MATCH ...  eg '{foo="bar",baz=~".*blip"}'
```



# Labels

标签是键值对，可以定义为任何东西！我们喜欢将它们称为元数据来描述日志流。如果您熟悉 Prometheus，您会看到一些标签，例如`job`和`instance`，我将在接下来的示例中使用它们。

我们为 Loki 提供的scrape配置也定义了这些标签。如果您使用 Prometheus，在 Loki 和 Prometheus 之间拥有一致的标签是 Loki 的超能力之一，这使得将您的[应用程序指标与日志数据关联](https://grafana.com/blog/2019/05/06/how-loki-correlates-metrics-and-logs-and-saves-you-money/)起来非常容易。

## Loki如何使用标签

Loki 中的标签执行一项非常重要的任务：它们定义一个stream。更具体地说，每个标签的键值的组合定义了流。如果只有一个标签值发生变化，则会创建一个新流。

如果您熟悉 Prometheus，那里使用的术语是series；但是 Prometheus 还有一个额外的维度：metric name。Loki 简化了这一点，因为没有metric name，只有标签，我们决定使用stream而不是series。

## Loki标签演示

这一系列示例将说明 Loki 中标签的基本用例和概念。

举个例子：

```yaml
scrape_configs:
 - job_name: system
   pipeline_stages:
   static_configs:
   - targets:
      - localhost
     labels:
      job: syslog
      __path__: /var/log/syslog
```

此配置将追踪一个文件并分配一个标签：`job=syslog`. 你可以这样查询：

```LogQL
{job=”syslog”}
```

这将在 Loki 中创建一个流。

现在让我们稍微扩展一下这个例子：

```yaml
scrape_configs:
 - job_name: system
   pipeline_stages:
   static_configs:
   - targets:
      - localhost
     labels:
      job: syslog
      __path__: /var/log/syslog
 - job_name: system
   pipeline_stages:
   static_configs:
   - targets:
      - localhost
     labels:
      job: apache
      __path__: /var/log/apache.log
```

现在我们正在跟踪两个文件。每个文件只有一个标签和一个值，因此 Loki 现在将存储两个流。

我们可以通过以下几种方式查询这些流：

```LogQL
{job=”apache”} <- show me logs where the job label is apache
{job=”syslog”} <- show me logs where the job label is syslog
{job=~”apache|syslog”} <- show me logs where the job is apache **OR** syslog
```

在最后一个示例中，我们使用正则表达式标签匹配器记录使用带有两个值的作业标签的流。现在考虑如何使用附加标签：

```yaml
scrape_configs:
 - job_name: system
   pipeline_stages:
   static_configs:
   - targets:
      - localhost
     labels:
      job: syslog
      env: dev
      __path__: /var/log/syslog
 - job_name: system
   pipeline_stages:
   static_configs:
   - targets:
      - localhost
     labels:
      job: apache
      env: dev
      __path__: /var/log/apache.log
```

现在不使用正则表达式，我们可以这样做：

```
{env=”dev”} <- will return all logs with env=dev, in this case this includes both log streams
```

希望现在您开始看到标签的力量。通过使用单个标签，您可以查询多个流。通过组合多个不同的标签，您可以创建非常灵活的日志查询。

标签是 Loki 日志数据的索引。它们用于查找压缩的日志内容，这些内容作为块单独存储。标签和值的每个独特组合都定义了一个流，流的日志被批处理、压缩并存储为块。

为了让 Loki 高效且具有成本效益，我们必须负责任地使用标签。下一节将更详细地探讨这一点。

## 基数

前面的两个示例使用静态定义的标签和单个值；但是，有一些方法可以动态定义标签。让我们看看如何使用Apache日志和一个大型正则表达式来解析这样的日志行：

```log
11.11.11.11 - frank [25/Jan/2000:14:00:01 -0500] "GET /1986.js HTTP/1.1" 200 932 "-" "Mozilla/5.0 (Windows; U; Windows NT 5.1; de; rv:1.9.1.7) Gecko/20091221 Firefox/3.5.7 GTB6"
```

```yaml
- job_name: system
   pipeline_stages:
      - regex:
        expression: "^(?P<ip>\\S+) (?P<identd>\\S+) (?P<user>\\S+) \\[(?P<timestamp>[\\w:/]+\\s[+\\-]\\d{4})\\] \"(?P<action>\\S+)\\s?(?P<path>\\S+)?\\s?(?P<protocol>\\S+)?\" (?P<status_code>\\d{3}|-) (?P<size>\\d+|-)\\s?\"?(?P<referer>[^\"]*)\"?\\s?\"?(?P<useragent>[^\"]*)?\"?$"
    - labels:
        action:
        status_code:
   static_configs:
   - targets:
      - localhost
     labels:
      job: apache
      env: dev
      __path__: /var/log/apache.log
```

这个正则表达式匹配日志行的每个组件，并将每个组件的值提取到一个捕获组中。在管道代码内部，这些数据被放置在一个临时数据结构中，该结构允许在处理该日志行期间将其用于多种目的（此时临时数据被丢弃）。关于这一点的更多细节可以在[Promtail 管道](clients.md#promtail/pipelines/)文档中找到。

在这个正则表达式中，我们将使用两个捕获组根据日志行本身的内容动态设置两个标签：

action (例如 action=”GET”, action=”POST”) status_code (例如 status_code=”200”, status_code=”400”)

现在让我们来看几个例子：

```nohighlight
11.11.11.11 - frank [25/Jan/2000:14:00:01 -0500] "GET /1986.js HTTP/1.1" 200 932 "-" "Mozilla/5.0 (Windows; U; Windows NT 5.1; de; rv:1.9.1.7) Gecko/20091221 Firefox/3.5.7 GTB6"
11.11.11.12 - frank [25/Jan/2000:14:00:02 -0500] "POST /1986.js HTTP/1.1" 200 932 "-" "Mozilla/5.0 (Windows; U; Windows NT 5.1; de; rv:1.9.1.7) Gecko/20091221 Firefox/3.5.7 GTB6"
11.11.11.13 - frank [25/Jan/2000:14:00:03 -0500] "GET /1986.js HTTP/1.1" 400 932 "-" "Mozilla/5.0 (Windows; U; Windows NT 5.1; de; rv:1.9.1.7) Gecko/20091221 Firefox/3.5.7 GTB6"
11.11.11.14 - frank [25/Jan/2000:14:00:04 -0500] "POST /1986.js HTTP/1.1" 400 932 "-" "Mozilla/5.0 (Windows; U; Windows NT 5.1; de; rv:1.9.1.7) Gecko/20091221 Firefox/3.5.7 GTB6"
```

在 Loki 中，将创建以下流：

```
{job=”apache”,env=”dev”,action=”GET”,status_code=”200”} 11.11.11.11 - frank [25/Jan/2000:14:00:01 -0500] "GET /1986.js HTTP/1.1" 200 932 "-" "Mozilla/5.0 (Windows; U; Windows NT 5.1; de; rv:1.9.1.7) Gecko/20091221 Firefox/3.5.7 GTB6"
{job=”apache”,env=”dev”,action=”POST”,status_code=”200”} 11.11.11.12 - frank [25/Jan/2000:14:00:02 -0500] "POST /1986.js HTTP/1.1" 200 932 "-" "Mozilla/5.0 (Windows; U; Windows NT 5.1; de; rv:1.9.1.7) Gecko/20091221 Firefox/3.5.7 GTB6"
{job=”apache”,env=”dev”,action=”GET”,status_code=”400”} 11.11.11.13 - frank [25/Jan/2000:14:00:03 -0500] "GET /1986.js HTTP/1.1" 400 932 "-" "Mozilla/5.0 (Windows; U; Windows NT 5.1; de; rv:1.9.1.7) Gecko/20091221 Firefox/3.5.7 GTB6"
{job=”apache”,env=”dev”,action=”POST”,status_code=”400”} 11.11.11.14 - frank [25/Jan/2000:14:00:04 -0500] "POST /1986.js HTTP/1.1" 400 932 "-" "Mozilla/5.0 (Windows; U; Windows NT 5.1; de; rv:1.9.1.7) Gecko/20091221 Firefox/3.5.7 GTB6"
```

这四个日志行将成为四个独立的流并开始填充四个独立的块。

与这些标签/值组合匹配的任何其他日志行都将添加到现有流中。如果出现另一个唯一的标签组合（例如 status_code=”500”），则会创建另一个新流。

现在想象一下，如果你为`ip`设置了一个标签。不仅用户的每一个请求都成为一个唯一的流。来自同一用户的每个具有不同操作或 status_code 的请求都将获得自己的流。

快速计算一下，如果可能有四个常见操作（GET、PUT、POST、DELETE）和四个常见状态代码（尽管可能不止四个！），这将是 16 个流和 16 个单独的块。如果我们使用`ip`的标签，您可以快速拥有数千或数万个流。

这种状态是高基数。这会干掉Loki。

当我们谈论**基数**时，我们指的是标签和值的组合以及它们创建的流的数量。

高基数会导致 Loki 建立一个巨大的索引（读取：$$$$）并将数千个小块刷新到对象存储（读取：慢）。Loki 目前在此配置中的性能非常差，而且成本效益最低，运行和使用起来也最没有乐趣。

## 并行化的Loki最佳性能

现在您可能会问：如果使用大量标签或带有大量值的标签不好，那么我应该如何查询我的日志？如果没有数据被索引，查询不是很慢吗？

当我们看到使用Loki的人习惯了其他索引繁重的解决方案时，他们似乎觉得有义务定义很多标签，以便有效地查询他们的日志。毕竟很多其他的日志解决方案都是关于索引的，这是常见的思维方式。

使用 Loki 时，您可能需要忘记您所知道的内容，看看如何通过并行化以不同的方式解决问题。Loki 的超能力是将查询分解成小块并并行调度它们，这样您就可以在很短的时间内查询大量的日志数据。

这种暴力手段听起来可能不太理想，但让我来解释一下为什么会这样。

大型索引既复杂又昂贵。通常，日志数据的全文索引与日志数据本身的大小相同或更大。要查询日志数据，您需要加载此索引，并且为了性能，它可能应该在内存中。这是很难扩展的，并且随着您收集更多日志时，您的索引会迅速变大。

现在让我们谈谈 Loki，其中的索引通常比您收集的日志量小一个数量级。因此，如果您在流和块保持在最低水平方面做得很好，那么与收集的日志相比，索引增长非常缓慢。

Loki 将有效地保持尽可能低的静态成本（索引大小和内存要求以及静态日志存储），并使查询性能在运行时可以通过水平扩展进行控制。

要了解其工作原理，让我们回顾一下查询访问日志数据以获取特定 IP 地址的示例。我们不想使用标签来存储 IP。相反，我们使用[过滤器表达式](logql.md#filter-expression)来查询它：

```
{job=”apache”} |= “11.11.11.11”
```

在后台，Loki 将该查询分解为更小的部分（分片），并为标签匹配的流打开每个块并开始查找此 IP 地址。

这些分片的大小和并行化的数量是可配置的，并且基于您提供的资源。如果你愿意，你可以将分片间隔配置为 5m，部署 20 个查询器，能在几秒钟内处理GB的日志。或者您可以疯狂地提供 200 个查询器并处理数TB的日志！

较小索引和并行暴力查询与较大/更快的全文索引之间的这种折中使 Loki 与其他系统相比可以节省成本。操作大型索引的成本和复杂性很高，而且通常是固定的——无论您是否查询，您都需要一直付出成本。

这种设计的好处意味着您可以决定想要拥有多少查询能力，并且可以根据需要进行更改。查询性能取决于您想花多少成本。同时，数据被高度压缩并存储在如 S3 和 GCS这种低成本的对象存储中。这将固定运营成本降至最低，同时仍拥有令人难以置信的快速查询能力。



# Troubleshooting

## Troubleshooting Loki

### Loki: Bad Gateway. 502

当将 Loki 添加为数据源时，Grafana中可能会出现此错误，表明Grafana无法连接到 Loki。可能原因如下：

- 如果 Loki 与 Docker 一起部署，并且 Grafana 和 Loki 不在同一节点上运行，请检查您的防火墙以确保节点可以连接。
- 如果 Loki 与 Kubernetes 一起部署：
  - 如果 Grafana 和 Loki 在同一命名空间中，请将 Loki URL 设置为 `http://$LOKI_SERVICE_NAME:$LOKI_PORT`
  - 否则，将 Loki URL 设置为 `http://$LOKI_SERVICE_NAME.$LOKI_NAMESPACE:$LOKI_PORT`

### Data source connected, but no labels received. Verify that Loki and Promtail is configured properly.

当将 Loki 添加为数据源时，Grafana 中可能会出现此错误，表明虽然 Grafana 已连接到 Loki，但 Loki 尚未收到来自 Promtail 的任何日志。可能原因如下：

- Promtail 正在运行并收集日志，但无法连接到 Loki 以发送日志。检查 Promtail 的输出。
- Promtail 在 Loki 准备好之前就开始向 Loki 发送日志。这可能发生在 Promtail 已经读取所有日志并将它们发送出去的测试环境中。您可以执行以下操作：
  - 在 Loki 之后启动 Promtail，例如 60 秒后。
  - 要强制 Promtail 重新发送日志消息，请删除positions文件（默认位置`/tmp/positions.yaml`）。
- 由于配置问题，Promtail 忽略目标并且不读取任何日志。
  - 这可以通过在 Promtail 中打开调试日志记录并查找`dropping target, no labels`或`ignoring target`消息来检测。
- Promtail 找不到您的日志文件的位置。检查是否 `scrape_configs`包含用于在工作程序节点上查找日志的有效路径设置。
- 您的 pod 使用的标签与 Promtail 配置为读取的标签不同。检查`scrape_configs`以验证。

## Troubleshooting targets

Promtail 开放了两个网页，可用于了解其服务发现的工作原理。

服务发现页面 ( `/service-discovery`) 显示所有发现的目标及其重新标记前后的标签以及target被删除的原因。

目标页面 ( `/targets`) 仅显示正在被主动抓取的目标及其各自的标签、文件和位置。

在 Kubernetes 上，您可以通过在本地转发 Promtail 端口（如果使用 Helm则为`9080`或者`3101`）来访问这两个页面：

```bash
$ kubectl port-forward loki-promtail-jrfg7 9080
# Then, in a web browser, visit http://localhost:9080/service-discovery
```

## 输出Debug

loki 和 promtail 都支持命令行上的日志级别flag：

```bash
$ loki —log.level=debug
$ promtail -log.level=debug
```

## 无法创建目标，ioutil.ReadDir: readdirent: not a directory

Promtail配置`__path__`包含指向找不到的目录条目。

## 连接到 Promtail pod 进行故障排除

首先检查上面的[Troubleshooting targets](快速入门.md#troubleshooting#troubleshooting targets)部分。如果这不能帮助回答您的问题，您可以连接到 Promtail pod 进行进一步排查。

如果您在集群中将 Promtail 作为 DaemonSet 运行，那么您将在每个节点上都有一个 Promtail pod，因此请确定您需要先调试哪个 Promtail：

```shell
$ kubectl get pods --all-namespaces -o wide
NAME                                   READY   STATUS    RESTARTS   AGE   IP             NODE        NOMINATED NODE
...
nginx-7b6fb56fb8-cw2cm                 1/1     Running   0          41d   10.56.4.12     node-ckgc   <none>
...
promtail-bth9q                         1/1     Running   0          3h    10.56.4.217    node-ckgc   <none>
```

该输出被截断以仅突出显示我们感兴趣的两个 pod，您可以使用`-o wide`标志看到它们正在运行的节点。

您需要将您感兴趣的 pod 的节点（在此示例中为 NGINX）与在同一节点上运行的 Promtail 进行匹配。

要调试，您可以连接到 Promtail pod：

```shell
kubectl exec -it promtail-bth9q -- /bin/sh
```

连接后，验证`/etc/promtail/promtail.yml`中的配置是否包含您期望的内容。

还要检查`/var/log/positions.yaml`（由 Helm 部署时是`/run/promtail/positions.yaml`或通过`positions.file`指定的任何值）并确保 Promtail 正在跟踪您期望的日志。

您可以通过查看Promtail 容器日志`/var/log/containers`来检查Promtail 日志。

## 为 Loki 启用跟踪

通过将环境变量`JAEGER_AGENT_HOST`设置为运行 Loki 的主机名和端口，可以使用[Jaeger](https://www.jaegertracing.io/)跟踪Loki。

如果使用 Helm 部署，请使用以下命令：

```bash
$ helm upgrade --install loki loki/loki --set "loki.tracing.jaegerAgentHost=YOUR_JAEGER_AGENT_HOST"
```

