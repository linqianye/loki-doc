# Loki概述

Grafana Loki 是一组可以组成一个功能齐全的日志堆栈的组件。

与其他日志系统不同，Loki 的构建思想是只为日志建立索引标签，而不对原始日志消息进行索引。这意味着 Loki 的运营成本更低，而且效率可以提高几个数量级。

有关同一文档的更详细版本，请阅读[架构](架构.md)。

## 多租户

Loki 支持多租户，因此租户之间的数据是完全分离的。多租户是通过租户ID（表示为字母数字字符串）实现的。当多租户模式被禁用时，所有请求都会在内部被赋予给租户ID为”false“。

## 操作模式

Loki 针对本地运行（或小规模运行）和水平扩展都进行了优化：Loki 提供了一种单一进程模式，可以在一个进程中运行所有所需的微服务。单进程模式非常适合测试 Loki 或小规模运行。对于水平可扩展性，Loki 的微服务可以被分解成不同的进程，允许它们彼此独立地扩展。

## 组件

### Distributor

Distributor服务负责响应处理客户端发送的日志。它本质上是日志数据写入路径中的“第一站”。一旦 distributor 接收到日志数据，它就会将它们分成批次并并将它们并行的发送到多个[ingesters](概述.md#Ingester)。

Distributor 通过[gRPC](https://grpc.io/)与 ingester 通信。它们是无状态的，可以根据需要进行扩张和收缩。

### 哈希散列

Distributors 使用一致的散列和可配置的复制因子来确定 ingester 服务的哪些实例应该接收日志数据。

哈希是基于日志标签和租c户 ID 的组合。

利用[consul](https://www.consul.io/)中存储的哈希环实现一致性哈希；所有 ingester 都使用他们拥有的一组令牌将自己注册到哈希环中。然后 Distributors 找到与日志哈希值最匹配的令牌，并将数据发送给该令牌的所有者。

### 仲裁一致性

由于所有 distributor 共享对同一个哈希环的访问权限，因此可以将写入请求发送到任何一个distributor。

为确保查询结果一致，Loki 在读写操作时使用 [Dynamo 风格](https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf) 的仲裁一致性。这意味着distributor将等待至少二分之一个周期加上一个 ingester 的时间，然后才能将响应数据发送给用户。

### Ingester

Ingester 服务负责将日志数据写入到持久存储的后端（DynamoDB、S3、Cassandra等）。

Ingester 将验证收集到的日志行是否正常。当 ingester 收到不符合预期顺序的日志行时，该行将被拒绝并向用户返回错误。有关更多信息，请参阅[时间戳排序](概述#时间戳排序)部分。

Ingester 会验证收集的日志行是否是按时间戳升序接收的（即每个日志都有一个时间戳，该时间戳出现的时间应该晚于它之前的日志）。当 ingester 收到不遵循此顺序的日志时，该行日志将被拒绝并返回错误。

来自每一组唯一标签的日志在内存中构建为“chunks(块)”，然后刷新到后端的备份存储。

如果一个 ingester 进程崩溃或突然退出，所有尚未刷新的数据都将丢失。Loki 通常被配置为复制每个日志为多个副本（通常为 3 个）来降低这种风险。

### 时间戳排序

通常，指定流（标签的唯一组合）推送到 Loki 的所有行必须具有比之前收到的行更加新的时间戳。但是，有两种情况用于处理具有相同纳秒时间戳的同一流的日志：

1. 如果传入的行与之前收到的行完全匹配（匹配之前的时间戳和日志文本），则传入的行将被视为完全重复并被忽略。
2. 如果传入的行与前一行具有相同的时间戳但内容不同，则接受日志行。这意味着同一时间戳可能有两个不同的日志行。

### 切换

默认情况下，当 ingester 关闭并尝试离开哈希环时，哈希环将等待查看是否有新的 ingester 在刷新之前尝试进入如果有则尝试启动切换。切换会将离开的 ingester 拥有的所有令牌和内存中的块转移到新的 ingester。

这个过程用来避免在关闭时刷新所有的chunk，这是一个缓慢的过程。

### 文件系统支持

虽然 ingester 确实支持通过 BoltDB 写入文件系统，但这只适用于单进程模式，因为[查询器](概述.md#查询器)需要访问相同的后端存储，而 BoltDB 只允许一个进程在给定时间锁定数据库。

### 查询器

queryer 服务处理存储在持久存储中的日志的实际[LogQL](logql.md)计算。

在回退到从后端存储加载数据之前，它首先尝试查询内存中的所有 ingester 的数据。

### 查询前端

query-frontend 服务是在查询池前面的一个可选组件。它负责公平地调度查询请求，在尽可能的情况下并行处理并缓存。

## 块存储

块存储是 Loki 的长期数据存储，旨在支持交互式查询和持续写入，无需后台维护任务。它包括：

- 块索引。该索引可由 Amazon Web Services 的 [DynamoDB](https://aws.amazon.com/dynamodb)、 Google Cloud Platform 的 [Bigtable](https://cloud.google.com/bigtable) 或 [Apache Cassandra ](https://cassandra.apache.org/) 提供支持。
- 块数据本身的键值 (KV) 存储，可以是 DynamoDB、Bigtable、Cassandra，也可以是Amazon 的 [S3](https://aws.amazon.com/s3)等对象存储。

> 与 Loki 的其他核心组件不同，块存储不是一个单独的服务、作业或进程，而是一个嵌入在需要访问 Loki 数据的两个服务（[ingester](https://grafana.com/docs/loki/v2.2.0/overview/#ingester)和[querier](https://grafana.com/docs/loki/v2.2.0/overview/#querier)）中的库。

块存储依赖于可用于支持块存储索引的“ [NoSQL](https://en.wikipedia.org/wiki/NoSQL) ”存储（DynamoDB、Bigtable 和 Cassandra）的统一接口。此接口假定索引是由以下项键入的条目的集合：

- **hash key**。这是所有读写操作所必需的。
- **range key**。这是写操作所必需的，读操作时可以省略，读操作可以通过前缀或范围查询。

该接口在支持的数据库中的工作方式略有不同：

- DynamoDB 本身支持范围和哈希。因此，索引条目直接建模为 DynamoDB 条目，散列键作为分布键，范围作为范围键。
- 对于 Bigtable 和 Cassandra，索引条目被建模为单独的列值。哈希键成为行键，范围键成为列键。

模式是用于将读写块存储时使用的匹配器和标签集映射到索引上的适当操作。随着 Loki 的发展，增加了模式，主要是为了更好地平衡写操作和提高查询性能。



# Loki 与其他日志系统的比较

## Loki/Promtail/Grafana vs EFK

EFK（Elasticsearch、Fluentd、Kibana）堆栈用于接收、展示和查询来自各种源的日志。

Elasticsearch 中的数据作为非结构化 JSON 对象存储在磁盘上。每个对象的键和每个键的内容都被索引。然后可以使用 JSON 对象来定义查询（称为Query DSL）或通过 Lucene 查询语言来查询数据。

相比之下，纯二进制模式的 Loki 可以将数据存储在磁盘上，但在水平可扩展模式下，数据可以存储在云存储系统中，例如 S3、GCS 或 Cassandra。日志以纯文本形式存储，并标有一组标签名称和值，其中只有标签对被索引。这种折中使得操作起来比完整索引更简单，并允许开发人员从他们的应用程序中直接发送日志。使用 [LogQL](logql.md) 查询 Loki 中的日志。但是，由于这种折中的设计，基于内容（即日志行中的文本）进行过滤的LogQL查询需要在搜索窗口中加载与查询中定义的标签匹配的所有块。

Fluentd 通常用于收集日志并将其转发到 Elasticsearch。Fluentd 被称为数据采集器，它可以从许多来源获取日志，然后对其进行处理，并将其转发到一个或多个目标。

相比之下，Promtail 是专门为 Loki 量身定制的。它的主要操作模式是发现存储在磁盘上的日志文件，并将它们与一组标签关联起来转发给 Loki。Promtail 可以为与 Promtail 运行在同一节点上的 Kubernetes pod 进行服务发现，充当容器 sidecar 或 Docker 日志驱动程序，从指定文件夹读取日志，并跟踪 systemd 日志。

Loki 通过一组标签对来表示日志的方式类似于 [Prometheus](https://prometheus.io/)表示指标的方式。当与 Prometheus 一起部署在环境中时，由于使用相同的服务发现机制，Promtail 的日志通常具有与应用程序指标相同的标签。拥有相同级别的日志和指标使用户能够在指标和日志之间无缝切换上下文，从而帮助进行根本原因分析。

Kibana 用于可视化和搜索 Elasticsearch 数据，在对这些数据进行分析方面非常强大。Kibana 提供了许多可视化工具来进行数据分析，例如位置图、用于异常检测的机器学习以及用于发现数据中关系的图形。当发生意外情况时可以配置警报来通知用户。

相比之下，Grafana 是专门为来自 Prometheus 和 Loki 等来源的时间序列数据量身定制的。可以设置仪表板来可视化指标（即将提供日志支持），并且可以使用 explore 视图对数据进行临时查询。与 Kibana 一样，Grafana 支持根据您的指标发出警报。



文档版本 v2.2.0