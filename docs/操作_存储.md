# Loki单一存储（boltdb-shipper 索引类型）

BoltDB Shipper 允许您在不依赖 NoSQL 存储的情况下运行 Loki 来存储索引。它在本地将索引存储在 BoltDB 文件中，并不断将这些文件传送到共享对象存储，即用于块存储的同一对象存储。它还不断将 BoltDB 文件从共享对象存储同步到配置的本地目录，以获取由同一 Loki 集群的其他服务创建的索引条目。这有助于以更少的依赖性运行 Loki 并节省存储成本，因为与托管 NoSQL 存储或运行自托管 Cassandra 实例的成本相比，对象存储可能要便宜得多。

**注意：** BoltDB shipper适合工作在24小时周期索引文件。对于已使用或即将使用的boltdb-shipper ，要求将索引周期设置为24 小时。如果 boltdb-shipper 已经创建了 7 天周期的索引文件，并且您想要保留以前的数据，那么只需使用 boltdb-shipper 用一个将来的日期添加一个新的模式配置，并把索引文件周期设置为 24 小时。

## 配置示例

GCS 配置示例：

```yaml
schema_config:
  configs:
    - from: 2018-04-15
      store: boltdb-shipper
      object_store: gcs
      schema: v11
      index:
        prefix: loki_index_
        period: 24h

storage_config:
  gcs:
    bucket_name: GCS_BUCKET_NAME

  boltdb_shipper:
    active_index_directory: /loki/index
    shared_store: gcs
    cache_location: /loki/boltdb-cache
```

这将运行使用 BoltDB Shipper 的Loki，将 BoltDB 文件存储在本地的`/loki/index`路径下并将块存储配置为 `GCS_BUCKET_NAME`。它还会定期将 BoltDB 文件传送到相同配置的存储桶中。它还会继续从其他 ingesters上传的共享存储桶中下载 BoltDB 文件到本地的`/loki/boltdb-cache`文件夹。

## 操作细节

Loki 可以配置为仅作为单个垂直扩展的实例或作为水平扩展的单个二进制（运行所有 Loki 服务）实例的集群运行，或者在微服务模式下仅在每个实例中运行一个服务。在读取和写入方面，Ingester是将索引和块写入存储，而Queriers则是从存储读取索引和块以服务请求。

在我们深入了解更多细节之前，了解 Loki 如何管理存储中的索引很重要。Loki 根据配置的时间段对索引进行分片，默认为 7 天。当涉及到基于表的存储（如 Bigtable/Cassandra/DynamoDB）时，每周会生成一个单独的表包含该周的索引。在 BolDB Shipper 的例子中，一个表由许多较小的 BoltDB 文件的集合组成，每个文件只存储 15 分钟的索引。每天创建的表由配置的`prefix_`+`<period-number-since-epoch>`标识。boltdb-shipper 的`<period-number-since-epoch>`将是自1970年1月1日以来的天数。例如，如果您将前缀设置为`loki_index_`并且在 2020 年 4 月 20 日收到写入请求，它将存储在名为 loki_index_18372 的表中，因为距1970年1月1日已经过去了`18371`天，而我们正处于`18372`日。由于索引的分片在使用BoltDB时会创建多个文件，因此 BoltDB Shipper 每天都会创建一个文件夹，并在该文件夹中添加当天的文件，并以创建它们的ingester命名这些文件。

为了减小文件的大小，提高传输速度和降低存储成本，使用 gzip 压缩后存储文件。

为了说明在共享对象存储中BoltDB文件的样子，让我们看在Loki集群中运行的2个名叫`ingester-0`和`ingester-1`的ingesters，他们都已经用 `loki_index_`前缀发送了第18371天和第18372天的文件，这里是文件的样子：

```
└── index
    ├── loki_index_18371
    │   ├── ingester-0-1587254400.gz
    │   └── ingester-1-1587255300.gz
    |   ...
    └── loki_index_18372
        ├── ingester-0-1587254400.gz
        └── ingester-1-1587254400.gz
        ...
```

**注意：**我们还在文件名中添加了时间戳，用随机化名称来避免在运行具有相同名称且没有持久存储的 Ingester 时覆盖文件。为简化起见，此处未显示时间戳。

让我们更深入地讨论在使用 BoltDB Shipper 运行 Ingesters 和 Querier 时它们是如何工作的。

### Ingesters

Ingesters 不断地将索引写入 BoltDB 文件的`active_index_directory`中，BoltDB Shipper 每 15 分钟在该目录中查找和更新新的文件，将它们上传到共享对象存储。在集群模式下运行 Loki 时，可能有多个 ingesters 服务于写入请求，因此每个 ingester都在本地生成 BoltDB 文件。

**注意：**为了避免在 Ingester 崩溃时索引丢失，建议将 Ingester 作为 statefulset（使用 k8s 时）运行，并使用持久存储来存储索引文件。

另一个需要注意的重要细节是，当块被刷新时，它们可以立即在对象存储中读取，而索引则不是，因为我们每 15 分钟才使用 BoltDB shipper上传它们一次。Ingester 公开了一个新的 RPC，用于让Queriers查询 Ingester 的本地索引来获取最近刷新的块，但其索引在Queriers中可能还不可用。对于所有需要从存储中读取块的查询，Queriers还通过 RPC 查询 Ingesters 来获取最近刷新的块的 ID，这是为了避免丢失查询中的任何日志。

### Queriers

Queriers将 BoltDB 文件从共享对象存储延迟加载到配置的`cache_location`. 当querier收到读取请求时，请求的查询范围将解析为周期范围，并且如果这些周期范围的所有文件尚未下载，都会下载到`cache_location`。下载文件一段时间后，我们会在共享对象存储中查找更新，默认情况下每 5 分钟下载一次。检查更新的频率可以通过`resync_interval`配置。

为了避免永远保留下载的索引文件，它们有一个默认为 24 小时的 ttl，这意味着如果一段时间内的索引文件在 24 小时内未使用，它们将从缓存位置中删除。ttl 可以使用`cache_ttl`进行配置。

**注意：**为了获得更好的读取性能并避免使用节点磁盘，建议将Queriers作为 statefulset（使用 k8s 时）运行，并使用持久存储来下载和查询索引文件。

### 禁用重复数据删除

Loki 分别使用 Chunks 和 WriteDedupe 缓存（使用ChunkStoreConfig配置）对块和索引执行重复数据消除。使用boltdb shipper时，重复数据删除的问题是，摄取器只会定期上载boltdb文件，以使其他所有服务都可以使用这些文件，这意味着有些服务可能会在很短的一段时间内尚未收到更新的索引。由此造成的问题是，如果第一个写入块和索引的 ingester 出现故障，并且作为复制方案一部分的所有其他 ingester，由于重复数据删除而跳过写入这些块和索引，我们最终会从查询响应中丢失这些日志，因为只有具有索引的ingester 故障。即使在非常常见的推送期间也会面临这个问题。

为避免这种情况，当复制因子大于 1 并且`boltdb-shipper`是活动或即将到来的索引类型时，Loki 禁用索引的重复数据删除。在使用`boltdb-shipper`时请避免配置WriteDedupe缓存，因为它纯粹用于索引重复数据删除，所以无论如何都不会使用到它。

### Compactor

Compactor 是 BoltDB Shipper 特定的服务，它通过删除重复索引并将所有文件合并到每个表一个文件来减小索引大小。我们建议运行 Compactor，因为单个 Ingester 每天创建 96 个文件，其中包括大量重复的索引条目，并且每个表查询多个文件会增加整体查询延迟。

**注意：**一次只能运行 1 个Compactor实例，否则可能会产生问题并可能导致数据丢失。

使用 GCS 的压缩器配置示例：

```yaml
compactor:
  working_directory: /loki/compactor
  shared_store: gcs

storage_config:
  gcs:
    bucket_name: GCS_BUCKET_NAME
```

#### 删除权限

Compactor是一个可选但建议使用的组件，用于组合和删除 boltdb-shipper 索引文件中的重复数据。压缩索引文件时，Compactor会写入一个新文件并删除未优化的文件。确保Compactor具有适当的删除文件权限，例如，AWS S3 的 s3:DeleteObject 权限。



# 文件系统

文件系统对象存储是最容易开始使用 Loki 的，但这种方法有一些优点和缺点。

它非常简单地将所有对象（块）存储在指定的目录中：

```yaml
storage_config:
  filesystem:
    directory: /tmp/loki/
```

为每个租户创建一个文件夹，一个租户的所有块都存储在该目录中。

如果 loki 是在单租户模式下运行，则所有块都放在一个名为`fake`的文件夹中，该文件夹是用于单租户模式的合成租户名称。

有关更多信息，请参阅[多租户](操作.md#multi-tenancy)。

## 优点

非常简单，与 BoltDB 索引存储配对时，无需额外的软件即可使用 Loki。

非常适合小批量应用程序、概念验证以及试用 Loki。

## 缺点

### 可扩展性

在某些情况下，一个目录中可以存储的块数是有限制的，例如查看[问题 #1502](https://github.com/grafana/loki/issues/1502)，它解释了 Loki 用户在文件存储区中使用大约550万个块文件的奇怪错误（还有一个问题的解决方法）。

但是，如果您将流保持在较低的数量（记住 loki 为每个流写入一个块）并使用`chunk_target_size`（大约 1MB）、`max_chunk_age`（增加超过 1 小时）、`chunk_idle_period`（增加以匹配`max_chunk_age`）之类的配置，则可以调整来减少刷新的块数量（尽管它们将消耗更多的内存）。

使用文件存储来存储数TB的日志数据仍然很有可能，但要意识到文件系统要在单个目录中存储的文件数量是有限制的。

### 持久性

对象的持久性取决于文件系统本身，其他对象存储（如 S3/GCS）在幕后做了很多工作，为您的数据提供极高的持久性。

### 高可用性

除非文件系统以某种方式（例如 NFS）共享，否则无法通过文件系统存储运行 Loki 集群。然而，就像几乎所有其他应用程序一样，使用共享文件系统可能会给 Loki 带来糟糕的体验。



# 表管理器

Loki 支持在基于表的数据存储中存储索引和块。使用这种存储类型时，会随时间创建多个表：每个表（也称为周期表）包含特定时间范围内的数据。

这种设计有两个主要优点：

1. **模式配置更改**：每个表都绑定到一个模式配置和版本，因此可以随着时间的推移引入更改，并且多个模式配置可以共存
2. **Retention**：retention 是通过删除整个表来实现的，这样可以进行快速的删除操作

**表管理器**是一个Loki组件，负责在周期表的时间段开始之前创建周期表，并在其数据时间范围超过保留期时删除它。

表管理器支持以下后端：

- 索引存储
  - [Single Store (boltdb-shipper)](操作_存储.md#Loki单一存储（boltdb-shipper 索引类型）)
  - [Amazon DynamoDB](https://aws.amazon.com/dynamodb)
  - [Google Bigtable](https://cloud.google.com/bigtable)
  - [Apache Cassandra](https://cassandra.apache.org/)
  - [BoltDB](https://github.com/boltdb/bolt)（主要用于本地环境）
- 块存储
  - [Amazon DynamoDB](https://aws.amazon.com/dynamodb)
  - [Google Bigtable](https://cloud.google.com/bigtable)
  - [Apache Cassandra](https://cassandra.apache.org/)
  - 文件系统（主要用于本地环境）

支持 Loki 用来存储块的对象存储（如 Amazon S3 和 Google Cloud Storage）不受表管理器管理，并且应设置自定义存储桶策略来删除旧数据。

有关配置表管理器的详细信息，请参阅 Loki 配置文档中的[表管理器](操作_存储.md#表管理器)部分。

## 表和模式配置

周期表存储与特定时间段相关的索引或块数据。单个表中存储的数据的时间范围及其存储类型在[`schema_config`](配置.md#模式配置)配置块中配置。

[`schema_config`](配置.md#模式配置)可以包含一个或多个配置块。每个配置都定义起始日期（格式为yyyy-mm-dd）到下一个配置之间使用的存储，如果是最后一个模式配置条目，则定义为“now”。

这允许在一段时间内有多个不重叠的模式配置，以便执行模式版本升级或更改存储设置（包括更改存储类型）。

![周期表](https://grafana.com/docs/loki/v2.2.0/operations/storage/table-manager-periodic-tables.png)

写入路径命中日志条目时间戳所在的表（除了靠近表末尾和下一个表开头的短时间段，通常是最后一个表），而读取路径命中包含查询时间范围数据的表。

### 模式配置示例

下面的`schema_config`定义了两个配置：第一个使用模式`v10`，当前一个使用`v11`.

第一个配置存储在`2019-01-01`和`2019-04-14`（包括）之间的数据，然后添加了一个新配置，将模式版本升级为`v11`。从`2019-04-15`开始使用模式`v11`存储数据。

对于每个配置，都会创建多个表，每个表存储一段时间（168小时=7天）的数据 。

```yaml
schema_config:
  configs:
    - from:   2019-01-01
      store:  dynamo
      schema: v10
      index:
        prefix: loki_
        period: 168h
    - from:   2019-04-15
      store:  dynamo
      schema: v11
      index:
        prefix: loki_
        period: 168h
```

### 创建表

表管理器在表开始时间之前创建新表，以确保在当前表达到结束时间时新表准备就绪。

 `table_manager`  配置块中的`creation_grace_period`属性定义了创建一个表的时间。

## 保留

由表管理器管理的保留在默认情况下是禁用的，因为它具有破坏性。您可以在配置中显式启用数据保留并设置`retention_period`大于零：

```yaml
table_manager:
  retention_deletes_enabled: true
  retention_period: 336h
```

表管理器通过删除超过`retention_period`的整个表的数据来实现保留。这种设计允许快速删除操作，代价是保留粒度由表的`period`控制.

如果每个表都包含一段时间的数据，并且删除了整个表，则表管理器将使用以下公式保持最后一个表的活动状态：

```
number_of_tables_to_keep = floor(retention_period / table_period) + 1
```

![保留](https://grafana.com/docs/loki/v2.2.0/operations/storage/table-manager-retention.png)

需要注意的是，由于内部实现的原因，表`period`和`retention_period`必须是24小时的倍数，才能获得预期的行为。

有关保留配置的详细信息，请参阅 [Loki Storage Retention](操作_存储.md#retention) 文档。

## 活动和非活动表

表可以是活动的或非活动的。

如果当前时间在以下范围内，则表被视为**活动**表：

- 表开始期 - [`creation_grace_period`](https://grafana.com/docs/loki/v2.2.0/configuration#table_manager_config)
- 表结束周期 + 最大块年龄（硬编码为`12h`）

![active_vs_inactive_tables](https://grafana.com/docs/loki/v2.2.0/operations/storage/table-manager-active-vs-inactive-tables.png)

目前，活动表和非活动表之间的区别**仅适用于 DynamoDB 存储**设置：容量模式（按需或预配置）、读/写容量单位和自动缩放。

| 动态数据库   | 活动表                            | 非活动表                                    |
| :----------- | :-------------------------------- | :------------------------------------------ |
| 容量模式     | `enable_ondemand_throughput_mode` | `enable_inactive_throughput_on_demand_mode` |
| 读取容量单元 | `provisioned_read_throughput`     | `inactive_read_throughput`                  |
| 写入容量单元 | `provisioned_write_throughput`    | `inactive_write_throughput`                 |
| 自动缩放     | 已启用（如果已配置）              | 始终禁用                                    |

## DynamoDB配置

使用表管理器配置 DynamoDB 时 ，读取的默认[按需预置](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html)容量单元设置为 300，写入的默认按需配置容量单元为 3000。可以覆盖默认值：

```yaml
table_manager:
  index_tables_provisioning:
    provisioned_write_throughput: 10
    provisioned_read_throughput: 10
  chunk_tables_provisioning:
    provisioned_write_throughput: 10
    provisioned_read_throughput: 10
```

如果表管理器不自动管理 DynamoDB，则旧数据无法轻易擦除，索引将无限增长。手动配置应确保主索引键设置为`h`（字符串），排序键设置为`r`（二进制）。配置 YAML 中的“period”属性应设置为`0`.

## 表管理器部署模式

表管理器可以通过以下两种方式执行：

1. 当 Loki 以单模式（单进程）运行时隐式执行
2. Loki 在微服务模式下运行时显式执行

### 单模式

当 Loki 在[单模式](架构.md#操作模式)下运行时，表管理器也作为整个堆栈的组件启动。

### 微服务模式

当 Loki 在[微服务模式](架构.md#操作模式)下运行时，表管理器应作为名为`table-manager`的单独服务启动。

您可以在 [`table-manager.libsonnet`](https://github.com/grafana/loki/tree/v2.2.0/production/ksonnet/loki/table-manager.libsonnet) 中查看生产级部署示例。



# Loki 存储保留

Loki 中的保留是通过[表管理器](操作_存储.md#表管理器)实现的。为了启用保留支持，需要配置表管理器来启用删除和保留期。请参阅 Loki 配置参考部分的[`table_manager_config`](配置.md#table_manager_config) 来获取所有可用选项。或者，可以使用`table-manager.retention-period`和 `table-manager.retention-deletes-enabled`命令行参数。提供的保留期需要是表示为可以使用 Go 的[time.Duration](https://golang.org/pkg/time/#ParseDuration)解析的字符串的持续时间。

> **警告**：保留期必须是[`period_config`](配置.md#period_config) 块中配置的索引和块表的`period`的倍数 。有关更多信息，请参阅[表管理器](操作_存储.md#表管理器)文档。

> **注意**：为避免查询超过保留期的数据，必须将[`chunk_store_config`](配置.md#chunk_store_config)中的 `max_look_back_period`设置为小于或等于`table_manager.retention_period` 中设置的值。

在使用 S3 或 GCS 时，存储块的存储桶需要正确设置到期策略。有关更多详细信息，请查看 [S3 的文档](https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html) 或 [GCS 的文档](https://cloud.google.com/storage/docs/managing-lifecycles)。

目前，只能全局设置保留策略。带有用于删除获取到的日志的API的针对每个租户的保留策略仍在开发中。

由于 Loki 的设计目标是降低存储日志的成本，因此优先考虑基于卷的删除 API。在此功能发布之前，如果您突然必须删除收集到的日志，则可以删除对象存储中的旧块。但是请注意，这只会删除日志内容并保持标签索引不变；您仍然可以看到相关标签，但无法检索已删除的日志内容。

有关表管理器内部结构的更多详细信息，请参阅 [表管理器](操作_存储.md#表管理器)文档。

## 示例配置

具有 28 天保留期的 GCS 配置示例：

```yaml
schema_config:
  configs:
  - from: 2018-04-15
    store: bigtable
    object_store: gcs
    schema: v11
    index:
      prefix: loki_index_
      period: 168h

storage_config:
  bigtable:
    instance: BIGTABLE_INSTANCE
    project: BIGTABLE_PROJECT
  gcs:
    bucket_name: GCS_BUCKET_NAME

chunk_store_config:
  max_look_back_period: 672h

table_manager:
  retention_deletes_enabled: true
  retention_period: 672h
```

##### 

# 预写日志(WAL)

Ingesters将数据临时存储在内存中。如果发生崩溃，可能会丢失数据。WAL 有助于填补可靠性方面的这一空白。

Loki 中的 WAL 记录传入数据并将其存储在本地文件系统上，以便在进程崩溃时保证已确认数据的持久性。重新启动后，在将自己注册为准备好进行后续写入前，Loki 将“重放”日志中的所有数据。这使 Loki 能够保持在内存中缓冲数据的性能和成本优势以及持久性优势（一旦确认写入操作，它就不会丢失数据）。

本节将使用 Kubernetes 作为示例中的参考部署范例。

## 声明及与其它WAL的区别

与您可能熟悉的其他 WAL 相比，Loki 中的 WAL需要一些特殊的权衡。WAL 旨在增加额外的持久性保证，但不以牺牲可用性为代价。但是有两种情况 WAL 会牺牲这些保证。

1. 在重放之前损坏或删除WAL

   如果 WAL 已损坏或部分删除，Loki 将无法恢复其所有数据。在这种情况下，Loki 将尝试恢复它能恢复的数据，但不会阻止 Loki 启动。

   注意：Prometheus 的指标`loki_ingester_wal_corruptions_total`可用于在发生这种情况时进行跟踪和警报。

2. 磁盘上没有剩余空间

   如果底层 WAL 磁盘已满，Loki 不会让传入的写入失败，但也不会将它们记录到 WAL。在这种情况下，跨进程重启的持久性保证将不起作用。

   注意：Prometheus 的指标`loki_ingester_wal_disk_full_failures_total`可用于在发生这种情况时进行跟踪和警报。

### 背压

WAL 还包括一个背压机制，允许在较小的内存范围内重放较大的 WAL。当 WAL 增长到超过它可以在内存中恢复的点时，在出现错误的情况（即停机）之后，这是很有帮助的。在这种情况下，ingester将跟踪正在重播的数据量，一旦超过`ingester.wal-replay-memory-ceiling`的阈值，就会刷新到存储。发生这种情况时，Loki 通过内容可寻址存储对数据块进行重复数据删除的尝试可能会受到影响。我们认为这种效率损失是一种可以接受的折衷，考虑到它如何简化操作，并且它不应该发生在常规操作（部署、重新调度）期间，在这种情况下，可以在不触发此阈值的情况下重放 WAL。

### 指标

## 部署变更

1. 由于ingesters需要在重新启动或拉起时具有相同的持久卷，因此所有ingesters都应在具有固定卷的[statefulset](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/)上运行。

2. 需要设置以下参数

   - `--ingester.wal-enabled`=`true`：允许在收集期间写入WAL。

   - `--ingester.wal-dir`指向存储和从恢复 WAL 数据的目录。请注意，这应该在已挂载的卷上。

   - `--ingester.checkpoint-duration` 到应该创建检查点的时间间隔。

   - `--ingester.recover-from-wal`=`true`：可从现有的WAL恢复数据。即使 WAL 被禁用并且设置为true ，数据也会恢复。需要为 WAL 指定目录。
     - 如果要启用 WAL，建议始终将其设置为`true`.
     
- `--ingester.wal-replay-memory-ceiling`（默认 4GB）可能会根据您的资源设置而设置的较高或者较低。它在 WAL 重放期间处理内存压力，允许重放比可用内存大很多倍的 WAL。这是为了在非常糟糕的情况下（即停机）将调节时间减至最少，并且可能不会影响正常运行和拉起。我们建议将其设置为可用内存的高百分比 (~75%)。

## 启用 WAL 时生命周期的变化

1. 在扩展或缩减期间会禁用将数据刷新到块存储。这是因为在 statefulset 的存在期间，没有同时离开和加入的ingester，而是同一个ingester被关闭并使用更新的配置再次返回。因此跳过刷新并从 WAL 中恢复数据。

## 磁盘空间需求

基于实际环境的测试：

- 一个 ingester有5000个连续的输入（5mb/s）。
- 检查点的周期为 5 分钟。
- 仅 WAL 磁盘上的磁盘利用率稳定在 10-15GB。

您不应100% 的使用磁盘。

## 从无状态部署迁移

不使用 WAL的 Ingester部署和使用WAL 的statefulset应该分别同步缩小和扩大，而不在它们之间传输数据，以确保迁移后的所有输入都是可靠的。

让我们以4个ingesters为例。迁移看起来像这样：

1. 启动一个有状态的ingester `ingester-0`并等待它准备好（接受读写请求）。
2. 将旧的 ingesters 缩小到 3个并等待离开的 ingester 将所有数据刷新到块存储。
3. 一旦该 ingester 从`kc get pods ...`中消失，添加另一个有状态的 ingester 并等待它准备就绪。现在你有`ingester-0`和`ingester-1`。
4. 重复步骤 2 来从旧部署中删除另一个ingester。
5. 重复步骤 3 来添加另一个有状态的ingester。现在你有`ingester-0 ingester-1 ingester-2`。
6. 重复第 4 步和第 5 步，您将最终拥有`ingester-0 ingester-1 ingester-2 ingester-3`.

## 如何扩大和缩小

### 扩大

向上扩展与没有 WAL 或 statefulsets 时所做的相同。这里没有什么可以改变的。

### 缩小

在缩小规模时，我们必须确保将离开的 ingesters 上的现有数据刷新到存储中，而不仅仅是在 WAL中。这是因为我们不会在不再存在的 ingesters 上重放 WAL，我们需要确保数据不是孤立的。

假设您有4个ingesters `ingester-0 ingester-1 ingester-2 ingester-3`并且想缩小到2个 ingesters，根据 statefulset 规则将关闭的 ingesters 是`ingester-3`，然后`ingester-2`。

因此，在 Kubernetes 中实际缩小之前，先将这些ingesters转发到[`/ingester/flush_shutdown`](https://grafana.com/docs/loki/v2.2.0/operations/api#post-ingesterflush_shutdown)。这将刷新块并将其从环中移除，之后它将注册为未准备好并可能被删除。

在命中`ingester-2 ingester-3`后，将ingesters缩小到2个。

## 补充笔记

### Kubernetes hacking

Statefulsets 的使用、升级等要麻烦得多。这在很大程度上源于规范中的不可变字段。例如，如果您想开始将 WAL 与单存储 Loki 一起使用，并希望为 WAL 和 boltdb-shipper 单独挂载卷，则在尝试更新 Kubernetes 状态集时可能会看到不变性错误。

在这种情况下，请尝试`kubectl -n <namespace> delete sts ingester --cascade=false`。这将使 pod 保持为活动状态，但会删除 statefulset。然后，您可以重新创建（更新后的）statefulset 并逐个开始按顺序删除`ingester-0`到`ingester-n`的pod ，从而允许 statefulset 启动新的 pod 以替换它们。

### 非Kubernetes或裸机部署

- 当ingester由于任何原因（升级、崩溃等）重新启动时，它应该能够连接到相同的卷以恢复 WAL 和令牌。
- 2 个ingesters不应使用相同卷或目录的WAL。
- Rollout 应该完全关闭一个 ingester，然后启动新的 ingester，而不是其他方式。