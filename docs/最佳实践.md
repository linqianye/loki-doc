# Loki标签的最佳实践

Loki 正在积极开发中，我们一直在努力提高性能。但这里有一些最新的标签最佳实践，它们将为您提供 Loki 的最佳体验。

## 1.推荐使用静态标签

诸如主机、应用程序和环境之类的都是很好的标签。对于给定的系统/应用程序，它们是固定的，并且具有明显的界限。使用静态标签可以更轻松地在逻辑意义上查询日志（例如，向我显示给定应用程序和特定环境的所有日志，或显示特定主机上所有应用程序的所有日志）。

## 2. 谨慎使用动态标签

标签值组合过多会导致流过多。在Loki中，这样做的缺点是存储了大量的索引和小尺寸的数据块，这反过来会降低 Loki 性能。

为避免这些问题，在你明确知道需要某个指标之前不要为它添加标签！使用过滤器表达式（|=“text”，|~“regex”）并强行获取这些日志。这样工作效率才高。

在一开始，我们就使用 promtail 管道为`level`设置了一个动态标签. 这对我们来说似乎很直观，因为我们经常只想显示`level=”error”`的日志；但是，我们现在正在重新评估它并变更为查询。事实证明，对于许多应用程序来说，`{app=”loki”} |= “level=error”`速度与`{app=”loki”,level=”error”}`一样快。

这看起来似乎很奇怪，但如果应用程序具有的容量不是很大，该标签会导致一个应用程序的日志被分成多达五个流，这意味要存储5倍的数据块。加载块会产生与之相关的开销。现在想象一下，如果该查询是`{app=”loki”,level!=”debug”}`，那将不得不加载比`{app=”loki”} != “level=debug”`更多的块。

上面，我们提到在你需要之前不要添加标签，那么你什么时候需要标签？再往下一点是关于 `chunk_target_size`的部分。如果您将其设置为 1MB（这是合理的），这将尝试以1MB的压缩大小切割块，这大约是5MB大小的未压缩日志（根据压缩情况可能高达10MB）。如果您的日志有足够的容量在少于`max_chunk_age`的时间内写入5MB的数据或在该时间范围内能写入多个块，您可能需要考虑将其拆分为带有动态标签的单独流。

在数据流处于空闲状态或在达到最大切片时间前，要避免将日志文件拆分为流，这会导致块被刷新。从[Loki 1.4.0 ](https://grafana.com/blog/2020/04/01/loki-v1.4.0-released-with-query-statistics-and-up-to-300x-regex-optimization/) 开始，有一个叫`sum by (reason) (rate(loki_ingester_chunks_flushed_total{cluster="dev"}[1m]))`的指标可以帮助您了解为什么要刷新块。

刷新时每个块是否已满并不重要，但它会在许多方面改善操作。因此，我们目前的指导方针是尽可能避免动态标签，而是使用过滤器表达式。例如，不要添加`level`动态标签，而是使用`|= “level=debug”`来代替。

## 3. 标签值必须始终有界限

如果您要设置动态标签，切勿使用具有没有界限或无限值的标签。这会给 Loki 带来大问题。

尝试将值限制在尽可能小的范围内。对于Loki能处理什么，我们没有完美的指导，但可以考虑动态标签值为个位数或者10的值。这对于静态标签不太重要。例如，如果您的环境中有1000台主机，那么拥有一个包含1000个值的主机标签就可以了。

## 4. 注意客户端使用的动态标签

Loki 有几个客户端选项：[Promtail](https://github.com/grafana/loki/tree/v2.2.0/docs/sources/clients/promtail)（它还支持systemd日志获取和基于TCP的syslog获取）、 [Fluentd](https://github.com/grafana/loki/tree/v2.2.0/fluentd/fluent-plugin-grafana-loki)、[Fluent Bit](https://github.com/grafana/loki/tree/v2.2.0/cmd/fluent-bit)、[Docker 插件](https://grafana.com/blog/2019/07/15/lokis-path-to-ga-docker-logging-driver-plugin-support-for-systemd/)等等！

每一个都提供了配置用于创建日志流的标签的方法。但请注意可能会应用哪些动态标签。可以使用 Loki Series API 来了解您的日志流是什么样子，看看是否有办法减少流和基数。可以通过[Series API](https://grafana.com/docs/loki/v2.2.0/api/#series)或者[logcli](https://grafana.com/docs/loki/v2.2.0/getting-started/logcli/)查询Series信息。

在 Loki 1.6.0 及以后版本中，logcli series 命令添加了专门用于调试高基数标签的`--analyze-labels`标志：

```
Total Streams:  25017
Unique Labels:  8

Label Name  Unique Values  Found In Streams
requestId   24653          24979
logStream   1194           25016
logGroup    140            25016
accountId   13             25016
logger      1              25017
source      1              25016
transport   1              25017
format      1              25017
```

在这个例子中，你可以看到`requestId`标签在24979个流中有24653个不同的值，这是错误的！

以下是这是一个不使用标签的完美例子，作为标签的`requestId`被删除，使用过滤器表达式来查询特定`requestId`日志。例如，如果在日志行中发现`requestId`为key=value的键值对，则可以编写如下查询：`{logGroup="group1"} |= "requestId=32422355"`

## 5.配置缓存

Loki 可以在多个级别缓存数据，这可以显着提高性能。这方面的详细信息将在以后的文档中介绍。

## 6. 日志必须按每个流递增的时间顺序排列

许多人在使用 Loki 时遇到的一个问题是他们的客户端接收到错误的无序的日志条目。这是因为 Loki 中有这条硬性规定：

- 对于任何单个日志流，日志必须始终以递增的时间顺序发送。如果收到的日志的时间戳早于为该流接收的最新日志，则该日志将被删除。

从这句话中可以剖析一些事情。第一个限制的是每个流。让我们看一个例子：

```
{job=”syslog”} 00:00:00 i’m a syslog!
{job=”syslog”} 00:00:01 i’m a syslog!
```

如果 Loki 收到的这两条是同一个流的，则一切都没问题。但是下面这个案例呢：

```
{job=”syslog”} 00:00:00 i’m a syslog!
{job=”syslog”} 00:00:02 i’m a syslog!
{job=”syslog”} 00:00:01 i’m a syslog!  <- Rejected out of order!
```

我们该怎么办呢？如果这些日志的来源是不同的系统怎么办？我们可以使用每个系统唯一的附加标签来解决这个问题：

```
{job=”syslog”, instance=”host1”} 00:00:00 i’m a syslog!
{job=”syslog”, instance=”host1”} 00:00:02 i’m a syslog!
{job=”syslog”, instance=”host2”} 00:00:01 i’m a syslog!  <- Accepted, this is a new stream!
{job=”syslog”, instance=”host1”} 00:00:03 i’m a syslog!  <- Accepted, still in order for stream 1
{job=”syslog”, instance=”host2”} 00:00:02 i’m a syslog!  <- Accepted, still in order for stream 2
```

但是，如果应用程序本身生成了乱序的日志怎么办？好吧，恐怕这是个问题。如果您使用[promtail pipeline stage](https://grafana.com/docs/loki/v2.2.0/clients/promtail/stages/timestamp/)之类的东西从日志行中提取时间戳，您可以让 Promtail 为日志行分配时间戳而不是提取时间戳。或者您希望可以在应用程序本身中修复它。

但我想使用Loki来解决这个问题！为什么你不能缓冲流并为我重新排序？！老实说，因为这会给 Loki 增加大量内存开销和复杂性，而且正如本文中的一个常见主题，我们希望 Loki 简单且经济高效。理想情况下，我们希望改进我们的客户端来做一些基本的缓冲和排序，因为这似乎是解决这个问题的更好的地方。

还值得注意的是，Loki 推送 API 的批处理特性可能会导致接收到一些乱序错误，这实际上是误报。（也许一个批次部分成功并且存在；或者之前成功的东西都会返回一个乱序条目；否则任何新的东西都会被接受。）

## 7. 使用 `chunk_target_size`

这是在[Loki v1.3.0](https://grafana.com/blog/2020/01/22/loki-1.3.0-released/)版本中添加的，我们已经对其进行了几个月的测试。我们现在在所有环境中都有`chunk_target_size: 1536000`。这会指示 Loki 尝试将所有块填充到1.5MB的目标压缩大小。这些较大的块使 Loki 的处理效率更高。

其他几个配置变量会影响块的填充程度。Loki 默认的`max_chunk_age`值为 1h，`chunk_idle_period`的值为30m，来限制使用的内存量以及进程崩溃时丢失日志的程度。

根据所使用的压缩方式（我们一直使用压缩性较低但性能较快的snappy），您需要5-10倍或7.5-10MB的原始日志数据来填充1.5MB的块。请记住，一个块就是一个流，您将日志文件拆分成的流越多，内存中的块就越多，并且在填充之前通过触发上面提到的超时，刷新它们的可能性就越大。

许多小的、未填充的块目前是 Loki 的 kryptonite。我们一直在努力改进这一点，并且在某些情况下可能会考虑使用压缩机制来改进这一点。但是总的来说，指导方针应该保持不变：尽力填充块！

如果您的应用程序可以足够快地记录日志以快速填充这些块（远小于`max_chunk_age`），那么使用动态标签将其分解为单独的流就变得更加合理。

## 8. 使用`-print-config-stderr`或`-log-config-reverse-order`

从 1.6.0 版开始，Loki 和 Promtail 都具有flag，它们将在启动时将整个配置对象转储到 stderr 或日志文件。

当直接运行loki时，`-print-config-stderr`是很好，例如，使用`./loki `您可以获得整个 Loki 配置的快速输出。

`-log-config-reverse-order` 是我们在所有环境中运行 Loki 时使用的标志，配置条目是反向的，以便在 Grafana 的 Explore 中查看时正确地从上到下读取配置的顺序。