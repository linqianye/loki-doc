# 操作Loki

1. [升级](操作.md#升级)
2. [认证](操作.md#使用Loki进行身份验证)
3. [查看](操作.md#查看Loki)
4. [扩展](操作.md#使用Loki扩展)
5. 贮存
   1. [表管理器](https://grafana.com/docs/loki/v2.2.0/operations/storage/table-manager/)
   2. [保留](https://grafana.com/docs/loki/v2.2.0/operations/storage/retention/)
6. [多租户](操作.md#多租户Loki)
7. [Loki Canary](操作.md#Loki Canary)

# 升级

**此页面已移动**

此页面已移至顶级[升级指南](升级.md)

此页面上的标题将保留用于现有链接。



# 使用Loki进行身份验证

Loki 不附带任何包含的身份验证层。操作员应该在您的服务前运行一个身份验证反向代理，例如使用basic auth的NGINX或 OAuth2 代理。

注意，在多租户模式下使用 Loki 时，Loki 要求将 HTTP 标头 `X-Scope-OrgID`设置为标识租户的字符串；应该由认证反向代理填充这个值。阅读[多租户](https://grafana.com/docs/loki/v2.2.0/operations/multi-tenancy/)文档以获取更多信息。

有关验证 Promtail 的信息，请参阅有关[如何配置 Promtail](https://grafana.com/docs/loki/v2.2.0/clients/promtail/configuration/)的文档。



# 查看Loki

Loki 和 Promtail 都暴露了一个暴露 Prometheus 指标的`/metrics`端点。您将需要一个本地 Prometheus 并将 Loki 和 Promtail 添加为target。请参阅[配置 Prometheus](https://prometheus.io/docs/prometheus/latest/configuration/configuration)获取更多信息。

Loki 的所有组件都暴露以下指标：

| 指标名称                        | 指标类型  | 描述                  |
| :------------------------------ | :-------- | :-------------------- |
| `log_messages_total`            | Counter   | Loki 记录的消息总数。 |
| `loki_request_duration_seconds` | Histogram | 收到的 HTTP 请求数。  |

Loki Distributors暴露以下指标：

| 指标名称                                          | 指标类型 | 描述                                                         |
| :------------------------------------------------ | :------- | :----------------------------------------------------------- |
| `loki_distributor_ingester_appends_total`         | Counter  | 发送到ingester的批次附加总数。                               |
| `loki_distributor_ingester_append_failures_total` | Counter  | 发送到ingester的失败批次附加总数。                           |
| `loki_distributor_bytes_received_total`           | Counter  | 每个租户收到的未压缩字节总数。                               |
| `loki_distributor_lines_received_total`           | Counter  | 每个租户收到的日志条目总数（不一定是行，因为一个条目可以有多于一行文本）。 |

Loki Ingesters 暴露以下指标：

| 指标名称                                     | 指标类型  | 描述                                                       |
| :------------------------------------------- | :-------- | :--------------------------------------------------------- |
| `cortex_ingester_flush_queue_length`         | Gauge     | 刷新队列中待处理的系列总数。                               |
| `cortex_chunk_store_index_entries_per_chunk` | Histogram | 每个块写入存储的索引条目数。                               |
| `loki_ingester_memory_chunks`                | Gauge     | 内存中的块总数。                                           |
| `loki_ingester_memory_streams`               | Gauge     | 内存中的流总数。                                           |
| `loki_ingester_chunk_age_seconds`            | Histogram | 刷新时块年龄的分布。                                       |
| `loki_ingester_chunk_encode_time_seconds`    | Histogram | 块编码时间的分布。                                         |
| `loki_ingester_chunk_entries`                | Histogram | 刷新时每个块的行分布。                                     |
| `loki_ingester_chunk_size_bytes`             | Histogram | 刷新时块大小的分布。                                       |
| `loki_ingester_chunk_utilization`            | Histogram | 刷新时块利用率的分布（填充的未压缩字节与最大未压缩字节）。 |
| `loki_ingester_chunk_compression_ratio`      | Histogram | 刷新时块压缩率的分布。                                     |
| `loki_ingester_chunk_stored_bytes_total`     | Counter   | 每个租户以块存储的总字节数。                               |
| `loki_ingester_chunks_created_total`         | Counter   | 在ingester中创建的块总数。                                 |
| `loki_ingester_chunks_stored_total`          | Counter   | 每个租户的总存储块。                                       |
| `loki_ingester_received_chunks`              | Counter   | 在切换过程中加入时此ingester发送的块总数。                 |
| `loki_ingester_samples_per_chunk`            | Histogram | 块中的样本数。                                             |
| `loki_ingester_sent_chunks`                  | Counter   | 在切换过程中离开时此ingester发送的块总数。                 |
| `loki_ingester_streams_created_total`        | Counter   | 每个租户创建的流总数。                                     |
| `loki_ingester_streams_removed_total`        | Counter   | 每个租户删除的流总数。                                     |

Promtail 暴露这些指标：

| 指标名称                                  | 指标类型  | 描述                                                     |
| :---------------------------------------- | :-------- | :------------------------------------------------------- |
| `promtail_read_bytes_total`               | Gauge     | 读取的字节数。                                           |
| `promtail_read_lines_total`               | Counter   | 读取的行数。                                             |
| `promtail_dropped_bytes_total`            | Counter   | 由于在所有重试后未能发送到ingester而丢弃的字节数。       |
| `promtail_dropped_entries_total`          | Counter   | 由于在所有重试后未能发送到ingester而被丢弃的日志条目数。 |
| `promtail_encoded_bytes_total`            | Counter   | 已编码并准备发送的字节数。                               |
| `promtail_file_bytes_total`               | Counter   | 从文件读取的字节数。                                     |
| `promtail_files_active_total`             | Counter   | 活动文件的数量。                                         |
| `promtail_log_entries_bytes`              | Histogram | 读取的字节总数。                                         |
| `promtail_request_duration_seconds_count` | Histogram | 发送请求的数量。                                         |
| `promtail_sent_bytes_total`               | Counter   | 发送的字节数。                                           |
| `promtail_sent_entries_total`             | Counter   | 发送到ingester的日志条目数。                             |
| `promtail_targets_active_total`           | Gauge     | 活动目标总数。                                           |
| `promtail_targets_failed_total`           | Counter   | 失败的目标总数。                                         |

这些指标中的大多数是counter，在正常操作期间应不断增加：

1. 您的应用程序向 Promtail 跟踪的文件发出日志行。
2. Promtail 读取新行并增加其计数器。
3. Promtail 将日志行转发到 Loki distributor，在那里接收到的计数器应该增加。
4. Loki distributor将日志行转发到 Loki ingester，请求持续时间计数器应该增加。

如果 Promtail 使用任何带有metrics阶段的管道，这些指标也将由 Promtail 在其`/metrics`端点公开。有关更多信息，请参阅 Promtail 关于[Pipelines](https://grafana.com/docs/loki/v2.2.0/clients/promtail/pipelines/)的文档 。

社区构建了一个示例Grafana dashboard示例，其名称为dashboard [10004](https://grafana.com/dashboards/10004)。

## Mixins

Loki 存储库有一个包括dashboards,、recording rules,和alerts的[mixin](https://github.com/grafana/loki/blob/v2.2.0/production/loki-mixin)。总之，mixin 为您提供了一个用于在生产中监控 Loki 的综合包。

有关 mixins 的更多信息，请查看[monitoring-mixins 项目](https://github.com/monitoring-mixins/docs)的文档 。



# 使用Loki扩展

有关Loki可扩展性的讨论，请查看 [Loki：受普罗米修斯启发的云原生开源日志记录](https://grafana.com/blog/2018/12/12/loki-prometheus-inspired-open-source-logging-for-cloud-natives/)。

在扩展 Loki 时，管理员应考虑按角色（ingester，distributor，querier）划分的多个 Loki 进程运行，而不是单个 Loki 进程。Grafana Labs 的[生产设置](https://github.com/grafana/loki/blob/v2.2.0/production/ksonnet/loki) 包含`.libsonnet`文件，该文件演示了如何配置单独组件和扩展资源使用。



# Loki存储

[高级存储概述](存储.md)在这里。

Loki 需要存储两种不同类型的数据：**块**和**索引**。

Loki 在不同的流中接收日志，其中每个流都由其租户 ID 和一组标签集唯一标识。当来自流的日志条目到达时，它们被压缩为“块”并保存在块存储中。有关块如何在内部存储，请参阅[块格式](操作.md#chunk-format)。

索引存储每个流的标签集，并将它们链接到各个块。

有关如何配置存储和索引的详细信息，请参阅 Loki 的[配置](配置.md)。

## 支持的存储

索引支持以下存储：

- [Single Store (boltdb-shipper)](操作.md#storage/boltdb-shipper/) 建议用于2.0及更新版本的索引存储，它在对象存储中存储boltdb索引文件
- [Amazon DynamoDB](https://aws.amazon.com/dynamodb)
- [Google Bigtable](https://cloud.google.com/bigtable)
- [Apache Cassandra](https://cassandra.apache.org/)
- [BoltDB](https://github.com/boltdb/bolt) （在集群 Loki 时不起作用）

块支持以下存储：

- [Amazon DynamoDB](https://aws.amazon.com/dynamodb)
- [Google Bigtable](https://cloud.google.com/bigtable)
- [Apache Cassandra](https://cassandra.apache.org/)
- [Amazon S3](https://aws.amazon.com/s3)
- [Google Cloud Storage](https://cloud.google.com/storage/)
- [Filesystem](操作.md#storage/filesystem/)（在用于生产数据之前，请阅读有关文件系统的更多信息，以了解优缺点）

## 云存储的权限

### S3

使用 S3 作为对象存储时，需要以下权限：

- `s3:ListBucket`
- `s3:PutObject`
- `s3:GetObject`
- `s3:DeleteObject` （如果运行 Single Store (boltdb-shipper) ）

资源：`arn:aws:s3:::<bucket_name>`，`arn:aws:s3:::<bucket_name>/*`

### DynamoDB

对索引存储使用 DynamoDB 时，需要以下权限：

- `dynamodb:BatchGetItem`
- `dynamodb:BatchWriteItem`
- `dynamodb:DeleteItem`
- `dynamodb:DescribeTable`
- `dynamodb:GetItem`
- `dynamodb:ListTagsOfResource`
- `dynamodb:PutItem`
- `dynamodb:Query`
- `dynamodb:TagResource`
- `dynamodb:UntagResource`
- `dynamodb:UpdateItem`
- `dynamodb:UpdateTable`
- `dynamodb:CreateTable`
- `dynamodb:DeleteTable`(如果`table_manager.retention_period`大于0s)

资源： `arn:aws:dynamodb:<aws_region>:<aws_account_id>:table/<prefix>*`

- `dynamodb:ListTables`

资源： `*`

#### 自动缩放

如果您从表管理器启用自动缩放，则需要以下权限：

##### 应用程序自动缩放

- `application-autoscaling:DescribeScalableTargets`
- `application-autoscaling:DescribeScalingPolicies`
- `application-autoscaling:RegisterScalableTarget`
- `application-autoscaling:DeregisterScalableTarget`
- `application-autoscaling:PutScalingPolicy`
- `application-autoscaling:DeleteScalingPolicy`

资源： `*`

##### IAM

- `iam:GetRole`
- `iam:PassRole`

资源： `arn:aws:iam::<aws_account_id>:role/<role_name>`

## 块格式

```
  -------------------------------------------------------------------
  |                               |                                 |
  |        MagicNumber(4b)        |           version(1b)           |
  |                               |                                 |
  -------------------------------------------------------------------
  |         block-1 bytes         |          checksum (4b)          |
  -------------------------------------------------------------------
  |         block-2 bytes         |          checksum (4b)          |
  -------------------------------------------------------------------
  |         block-n bytes         |          checksum (4b)          |
  -------------------------------------------------------------------
  |                        #blocks (uvarint)                        |
  -------------------------------------------------------------------
  | #entries(uvarint) | mint, maxt (varint) | offset, len (uvarint) |
  -------------------------------------------------------------------
  | #entries(uvarint) | mint, maxt (varint) | offset, len (uvarint) |
  -------------------------------------------------------------------
  | #entries(uvarint) | mint, maxt (varint) | offset, len (uvarint) |
  -------------------------------------------------------------------
  | #entries(uvarint) | mint, maxt (varint) | offset, len (uvarint) |
  -------------------------------------------------------------------
  |                      checksum(from #blocks)                     |
  -------------------------------------------------------------------
  |           metasOffset - offset to the point with #blocks        |
  -------------------------------------------------------------------
```

想要查询更多的信息，请查看：

1. [Single Store (boltdb-shipper)](操作_存储.md#boltdb-shipper)
2. [Filesystem](操作_存储.md#Filesystem)
3. [表管理器](操作_存储.md#storage/table-manager/)
4. [保留](操作_存储.md#storage/retention/)



# 多租户Loki

Loki 是一个多租户系统；租户 A 的请求和数据与租户 B 隔离。对 Loki API 的请求应包含一个 HTTP 标头 ( `X-Scope-OrgID`)，用于标识请求的租户。

租户 ID 可以是符合 Go HTTP 标头限制 (1MB) 的任何字母数字字符串。建议管理员使用合理的限制来唯一识别租户；20个字节通常就足够了。

要在多租户模式下运行，Loki 应该使用`auth_enabled: true`参数启动。

Loki 可以在不需要`X-Scope-OrgID`标头的“单租户”模式下运行。单租户模式下，租户ID默认为`fake`。



# Loki Canary

![金丝雀](https://grafana.com/docs/loki/v2.2.0/operations/canary.png)

Loki Canary是一个独立的应用程序，它可以审计Loki的日志捕获性能。

## 工作原理

![block_diagram](https://grafana.com/docs/loki/v2.2.0/operations/loki-canary-block.png)

Loki Canary将日志写入文件，并将时间戳存储到内部数组中。内容看起来是这样的：

```nohighlight
1557935669096040040 ppppppppppppppppppppppppppppppppppppppppppppppppppppppppppp
```

日志条目的相关部分是时间戳； `p`只是填充字节，用于配置日志的大小。

应该配置一个代理（比如Promtail）来读取日志文件并将其发送给Loki。

同时，Loki Canary会打开一个WebSocket连接到LokI并追踪它创建的日志。当在WebSocket接收到日志时，会将日志消息中的时间戳将和内部数组中的时间戳进行比较。

如果接收到的日志是：

- 如果收到的是数组中的下一个，它将从数组中删除，并将（当前时间-日志时间戳）记录在`response_latency` 直方图中。这是性能良好的日志的预期行为。
- 如果收到的不是数组中要接收的下一个，它将从数组中删除，响应时间记录在`response_latency`直方图中，并且`out_of_order_entries`计数器将递增。
- 如果它根本不在数组中，就将接收到的日志放到一个单独列表中进行检查，增加`duplicate_entries`计数器或`unexpected_entries`计数器。

在后台，Loki Canary 还运行着一个计时器，它遍历内部数组中的所有条目。如果任何条目的持续时间早于`-wait`标志指定的持续时间（默认为 60 秒），则会从数组中删除这些条目并且将`websocket_missing_entries`计数器递增。然后直接向Loki发起一个额外的查询来查找丢失的条目，以确定它们是真正丢失还是只在 WebSocket 中丢失。如果在直接查询中找不到丢失的条目，则`missing_entries`计数器递增。

### 其他查询

#### 抽查

从版本 1.6.0 开始，canary 将随着时间的推移抽查某些结果来确认它们存在于 Loki 中，这有助于测试内存中的日志通过 ingester 转换到 持久存储中，以确保没有丢失任何内容。

`-spot-check-interval`和`-spot-check-max`用于调节此功能， `-spot-check-interval`将以此间隔从流中提取日志条目并将其保存在单独的列表中，直到达到`-spot-check-max`的值.

对于 `-spot-check-query-rate`中的每一个， Loki 将为此列表中的每个条目进行查询并将 `loki_canary_spot_check_entries_total`递增，如果结果缺失，则`loki_canary_spot_check_missing_entries_total`则递增。

`spot-check-interval`的默认值为15m，`spot-check-max`的默认值为4h， 意味着在运行 Canary 4 小时后将有一个包含 16 个条目的列表，它将每分钟查询一次（默认`spot-check-query-rate`间隔为 1m），因此请注意如果有很多canary，这可能会给Loki带来的查询负载。

#### 指标测试

从版本 1.6.0 开始，canary 将运行一个指标查询`count_over_time`来验证存储在 Loki 中的日志的速率是否与canary创建日志的速率相对应。

`-metric-test-interval`和`-metric-test-range`用于调节此功能，但默认情况下，每15分钟 canary 都会运行`count_over_time`指标来对 Loki运行范围为24小时的即时查询。

如果canary没有运行`-metric-test-range`( `24h`)，则查询范围将调整为canary运行的时间，以便可以计算自canary启动以来的速率。

Canary 计算该范围内的预期日志数（也根据 Canary 运行时间进行调整），并将预期结果与 Loki 返回的实际结果进行比较。差值作为值存储在`loki_canary_metric_test_deviation`中。

预计会有一些偏差，基于查询率与实际查询数据相比，创建预期计算的方法不完善，会导致少数日志条目出现偏差。

预计偏差不会出现超过 3-4 个日志条目。

### 控制

Loki Canary 响应两个端点，允许动态挂起或恢复 Canary 进程。如果您想快速禁用或重启 Canary，这会很有用。要停止或启动Canary，请对`/suspend`或 `/resume`端点发出 HTTP GET 请求。

## 安装

### 二进制

Loki Canary 作为 GitHub上Loki发行版的一部分，提供了预编译二进制文件。

### Docker

Loki Canary 也提供了 Docker 容器镜像：

```bash
# change tag to the most recent release
$ docker pull grafana/loki-canary:2.0.0
```

### Kubernetes

要在 Kubernetes 上运行，可以执行以下简单操作：

```bash
kubectl run loki-canary --generator=run-pod/v1 --image=grafana/loki-canary:latest --restart=Never --image-pull-policy=IfNotPresent --labels=name=loki-canary -- -addr=loki:3100
```

或者您可以做一些更复杂的事情，例如将其部署为 DaemonSet，`production`文件夹中有一个用于此的 Tanka 设置，您可以使用`jsonnet-bundler`命令导入它 ：

```bash
jb install github.com/grafana/loki-canary/production/ksonnet/loki-canary
```

然后在您的 Tanka 环境的`main.jsonnet`中，您将需要这样的内容：

```jsonnet
local loki_canary = import 'loki-canary/loki-canary.libsonnet';

loki_canary {
  loki_canary_args+:: {
    addr: "loki:3100",
    port: 80,
    labelname: "instance",
    interval: "100ms",
    size: 1024,
    wait: "3m",
  },
  _config+:: {
    namespace: "default",
  }
}
```

#### 示例

以独立 Pod 实现loki-canary

```yaml
---
apiVersion: v1
kind: Pod
metadata:
  labels:
    app: loki-canary
    name: loki-canary
  name: loki-canary
spec:
  containers:
  - args:
    - -addr=loki:3100
    image: grafana/loki-canary:latest
    imagePullPolicy: IfNotPresent
    name: loki-canary
    resources: {}
---
apiVersion: v1
kind: Service
metadata:
  name: loki-canary
  labels:
    app: loki-canary
spec:
  type: ClusterIP
  selector:
    app: loki-canary
  ports:
  - name: metrics
    protocol: TCP
    port: 3500
    targetPort: 3500
```

以守护进程的方式实现loki-canary

```yaml
---
kind: DaemonSet
apiVersion: extensions/v1beta1
metadata:
  labels:
    app: loki-canary
    name: loki-canary
  name: loki-canary
spec:
  template:
    metadata:
      name: loki-canary
      labels:
        app: loki-canary
    spec:
      containers:
      - args:
        - -addr=loki:3100
        image: grafana/loki-canary:latest
        imagePullPolicy: IfNotPresent
        name: loki-canary
        resources: {}
---
apiVersion: v1
kind: Service
metadata:
  name: loki-canary
  labels:
    app: loki-canary
spec:
  type: ClusterIP
  selector:
    app: loki-canary
  ports:
  - name: metrics
    protocol: TCP
    port: 3500
    targetPort: 3500
```

### 源码安装

如果其他选项不足以满足您的用例，您可以自己编译`loki-canary` ：

```bash
# clone the source tree
$ git clone https://github.com/grafana/loki

# build the binary
$ make loki-canary

# (optionally build the container image)
$ make loki-canary-image
```

## 配置

Loki 的地址必须用`-addr`参数传入，如果您的 Loki 服务器使用 TLS，还必须提供`-tls=true`参数。请注意，使用 TLS 将导致 WebSocket 使用`wss://`连接而不是`ws://`.

还应该提供`-labelname`和`-labelvalue`参数，因为Loki Canary使用这些参数来过滤日志流，以便只处理当前Canary实例的日志。确保提供给参数的值对于 Loki Canary 的每个实例都是唯一的。Grafana Labs 的 Tanka 配置通过传入 pod 名称作为标签值来实现这一点。

如果 Loki Canary 报告大量`unexpected_entries`，则可能是Loki Canary 等待的时间不够长，`-wait`参数的值应增加到大于 60 秒的值。

**注意**`pruneinterval`和`interval`之间的关系。例如，如果间隔为 10 毫秒（每秒 100 条日志）和修剪间隔为 60 秒，则每分钟将写入 6000 条日志。如果这些日志不是通过WebSocket接收到的，那么canary将尝试直接查询Loki以查看它们是否完全丢失。**但是**，查询返回的结果限制为1000个，因此即使日志确实发送发到了Loki，也无法返回所有日志。

**同样**，如果您降低了`pruneinterval`则可能导致DoS攻击的风险，因为所有canaries都试图在您`pruneinterval`定义的位置查询丢失的日志。

所有选项：

```nohighlight
  -addr string
        The Loki server URL:Port, e.g. loki:3100
  -buckets int
        Number of buckets in the response_latency histogram (default 10)
  -interval duration
        Duration between log entries (default 1s)
  -labelname string
        The label name for this instance of loki-canary to use in the log selector (default "name")
  -labelvalue string
        The unique label value for this instance of loki-canary to use in the log selector (default "loki-canary")
  -metric-test-interval duration
        The interval the metric test query should be run (default 1h0m0s)
  -metric-test-range duration
        The range value [24h] used in the metric test instant-query. Note: this value is truncated to the running time of the canary until this value is reached (default 24h0m0s)
  -pass string
        Loki password
  -port int
        Port which loki-canary should expose metrics (default 3500)
  -pruneinterval duration
        Frequency to check sent vs received logs, also the frequency which queries for missing logs will be dispatched to loki, and the frequency spot check queries are run (default 1m0s)
  -query-timeout duration
        How long to wait for a query response from Loki (default 10s)
  -size int
        Size in bytes of each log line (default 100)
  -spot-check-interval duration
        Interval that a single result will be kept from sent entries and spot-checked against Loki, e.g. 15min default one entry every 15 min will be saved andthen queried again every 15min until spot-check-max is reached (default 15m0s)
  -spot-check-max duration
        How far back to check a spot check entry before dropping it (default 4h0m0s)
  -spot-check-query-rate duration
        Interval that the canary will query Loki for the current list of all spot check entries (default 1m0s)
  -streamname string
        The stream name for this instance of loki-canary to use in the log selector (default "stream")
  -streamvalue string
        The unique stream value for this instance of loki-canary to use in the log selector (default "stdout")
  -tls
        Does the loki connection use TLS?
  -user string
        Loki username
  -version
        Print this builds version information
  -wait duration
        Duration to wait for log entries before reporting them lost (default 1m0s)
```

